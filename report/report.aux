\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Serial Implementation}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data structures}{1}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A plot in log-log scale that shows serial without binning runs on $O(n^2)$ time and serial with binning runs in $O(n)$ time.}}{2}{figure.1}}
\newlabel{fig:serial-on}{{1}{2}{A plot in log-log scale that shows serial without binning runs on $O(n^2)$ time and serial with binning runs in $O(n)$ time}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Results}{2}{subsection.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}OpenMP implementation}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Synchronization}{2}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces $O(n)$ scaling of the OpenMP implementation with 12 threads compared to the serial implementation.}}{3}{figure.2}}
\newlabel{fig:openmp-on}{{2}{3}{$O(n)$ scaling of the OpenMP implementation with 12 threads compared to the serial implementation}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Strong scaling of the OpenMP implementation.}}{4}{figure.3}}
\newlabel{fig:openmp-strong}{{3}{4}{Strong scaling of the OpenMP implementation}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Weak scaling of the OpenMP implementation.}}{5}{figure.4}}
\newlabel{fig:openmp-weak}{{4}{5}{Weak scaling of the OpenMP implementation}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces $O(n)$ scaling of the MPI implementation.}}{6}{figure.5}}
\newlabel{fig:mpi-on}{{5}{6}{$O(n)$ scaling of the MPI implementation}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Weak scaling of the MPI implementation.}}{6}{figure.6}}
\newlabel{fig:mpi-weak}{{6}{6}{Weak scaling of the MPI implementation}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Results}{6}{subsection.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}MPI Implementation}{6}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Communication between nodes}{6}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Results}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Comparison of distributed and shared implementations}{6}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Where does the time go?}{6}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Discussion}{6}{subsection.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6}GPU Implementation}{6}{section.6}}
\newlabel{GPU}{{6}{6}{GPU Implementation}{section.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Strong scaling of the MPI implementation.}}{6}{figure.7}}
\newlabel{fig:mpi-strong}{{7}{6}{Strong scaling of the MPI implementation}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Speedup plots that show how closely parallel codes approach the idealized $p$-times speedup.}}{7}{figure.8}}
\newlabel{fig:speedup}{{8}{7}{Speedup plots that show how closely parallel codes approach the idealized $p$-times speedup}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A plot of the speedup of the GPU code versus the serial, openmp, mpi runs on the CPU of the node}}{7}{figure.9}}
\newlabel{fig:gpu-speedup}{{9}{7}{A plot of the speedup of the GPU code versus the serial, openmp, mpi runs on the CPU of the node}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Results}{7}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Discussion}{7}{subsection.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces A plot in log-log scale that shows the performance of your code versus the naive GPU code.}}{7}{figure.10}}
\newlabel{fig:gpu-naive}{{10}{7}{A plot in log-log scale that shows the performance of your code versus the naive GPU code}{figure.10}{}}
